diff --git a/term_frequency.py b/axioms/axiom/retrieval/term_frequency.py
index 144e118..b1a0c66 100644
--- a/term_frequency.py
+++ b/axioms/axiom/retrieval/term_frequency.py
@@ -1,145 +1,313 @@
-from dataclasses import dataclass
-from itertools import combinations
+from dataclasses import dataclass, field
+from itertools import chain, combinations
 from math import isclose
+from typing import AbstractSet, Final, Sequence, Union
+
+from injector import inject, NoInject
+from numpy import array, float_
+from tqdm.auto import tqdm
+
+from axioms.axiom.base import Axiom
+from axioms.axiom.precondition import PreconditionMixin
+from axioms.precondition.base import Precondition
+from axioms.precondition.length import LEN
+from axioms.axiom.utils import strictly_greater
+from axioms.model import PreferenceMatrix, Query, Document, Preference
+from axioms.tools import IndexStatistics, TermTokenizer, TextContents, TextStatistics
+from axioms.utils.lazy import lazy_inject
+
+
+@inject
+@dataclass(frozen=True, kw_only=True)
+class Tfc1Axiom(PreconditionMixin[Query, Document], Axiom[Query, Document]):
+    text_contents: TextContents[Union[Query, Document]]
+    term_tokenizer: TermTokenizer
+    text_statistics: TextStatistics[Document]
+    precondition: NoInject[Precondition[Query, Document]] = field(default_factory=LEN)
+    margin_fraction: float = 0.1
+
+    def _preference(
+        self,
+        term_frequency_sum1: float,
+        term_frequency_sum2: float,
+    ) -> Preference:
+        if isclose(
+            term_frequency_sum1,
+            term_frequency_sum2,
+            rel_tol=self.margin_fraction,
+        ):
+            return 0
 
-from ir_axioms.axiom.base import Axiom
-from ir_axioms.axiom.preconditions import LEN_Mixin
-from ir_axioms.axiom.utils import approximately_equal, strictly_greater
-from ir_axioms.model import Query, RankedDocument, IndexContext
-
-
-@dataclass(frozen=True)
-class _TFC1(Axiom):
+        return strictly_greater(term_frequency_sum1, term_frequency_sum2)
 
     def preference(
-            self,
-            context: IndexContext,
-            query: Query,
-            document1: RankedDocument,
-            document2: RankedDocument
-    ) -> float:
-        term_frequency1: float = 0
-        term_frequency2: float = 0
-        for qt in context.terms(query):
-            term_frequency1 += context.term_frequency(document1, qt)
-            term_frequency2 += context.term_frequency(document2, qt)
-
-        if approximately_equal(term_frequency1, term_frequency2):
-            # Less than 10% difference.
-            return 0
+        self,
+        input: Query,
+        output1: Document,
+        output2: Document,
+    ) -> Preference:
+        query_terms = self.term_tokenizer.terms(
+            self.text_contents.contents(input),
+        )
+
+        term_frequency_sum1 = sum(
+            self.text_statistics.term_frequency(output1, term) for term in query_terms
+        )
+        term_frequency_sum2 = sum(
+            self.text_statistics.term_frequency(output2, term) for term in query_terms
+        )
+
+        return self._preference(term_frequency_sum1, term_frequency_sum2)
+
+    def preferences(
+        self,
+        input: Query,
+        outputs: Sequence[Document],
+    ) -> PreferenceMatrix:
+
+        query_terms = self.term_tokenizer.terms(
+            self.text_contents.contents(input),
+        )
+
+        term_frequency_sums = [
+            sum(
+                self.text_statistics.term_frequency(output, term)
+                for term in query_terms
+            )
+            for output in tqdm(
+                outputs,
+                desc="Sum term frequencies",
+                unit="document",
+            )
+        ]
 
-        return strictly_greater(term_frequency1, term_frequency2)
+        return array(
+            [
+                self._preference(term_frequency_sum1, term_frequency_sum2)
+                for term_frequency_sum1 in term_frequency_sums
+                for term_frequency_sum2 in term_frequency_sums
+            ],
+            dtype=float_,
+        ).reshape((len(outputs), len(outputs)))
 
 
-@dataclass(frozen=True)
-class TFC1(LEN_Mixin, _TFC1):
-    name = "TFC1"
+TFC1: Final = lazy_inject(Tfc1Axiom)
 
 
-@dataclass(frozen=True)
-class _TFC3(Axiom):
+@inject
+@dataclass(frozen=True, kw_only=True)
+class Tfc3Axiom(PreconditionMixin[Query, Document], Axiom[Query, Document]):
+    text_contents: TextContents[Union[Query, Document]]
+    term_tokenizer: TermTokenizer
+    index_statistics: IndexStatistics
+    text_statistics: TextStatistics[Document]
+    precondition: NoInject[Precondition[Query, Document]] = field(default_factory=LEN)
+    margin_fraction: float = 0.1
 
     def preference(
-            self,
-            context: IndexContext,
-            query: Query,
-            document1: RankedDocument,
-            document2: RankedDocument
-    ) -> float:
+        self,
+        input: Query,
+        output1: Document,
+        output2: Document,
+    ) -> Preference:
+        query_unique_terms = self.term_tokenizer.unique_terms(
+            self.text_contents.contents(input),
+        )
+
         sum_document1 = 0
         sum_document2 = 0
-
-        query_terms = context.term_set(query)
-        for query_term1, query_term2 in combinations(query_terms, 2):
-            term_discrimination1 = context.inverse_document_frequency(
+        for query_term1, query_term2 in combinations(query_unique_terms, 2):
+            term_discrimination1 = self.index_statistics.inverse_document_frequency(
                 query_term1
             )
-            term_discrimination2 = context.inverse_document_frequency(
+            term_discrimination2 = self.index_statistics.inverse_document_frequency(
                 query_term2
             )
 
-            if approximately_equal(term_discrimination1, term_discrimination2):
-                d1q1 = context.term_frequency(document1, query_term1)
-                d2q1 = context.term_frequency(document2, query_term1)
-                d1q2 = context.term_frequency(document1, query_term2)
-                d2q2 = context.term_frequency(document2, query_term2)
+            if isclose(
+                term_discrimination1,
+                term_discrimination2,
+                rel_tol=self.margin_fraction,
+            ):
+                d1q1 = self.text_statistics.term_frequency(output1, query_term1)
+                d2q1 = self.text_statistics.term_frequency(output2, query_term1)
+                d1q2 = self.text_statistics.term_frequency(output1, query_term2)
+                d2q2 = self.text_statistics.term_frequency(output2, query_term2)
 
                 if d1q1 != 0 and d1q2 != 0:
-                    if isclose(d2q1, d1q1 + d1q2) and isclose(d2q2, 0):
+                    if isclose(d2q1, d1q1 + d1q2) and d2q2 == 0:
                         sum_document1 += 1
-                    if isclose(d2q2, d1q2 + d1q1) and isclose(d2q1, 0):
+                    if isclose(d2q2, d1q2 + d1q1) and d2q1 == 0:
                         sum_document1 += 1
                 if d2q1 != 0 and d2q2 != 0:
-                    if isclose(d1q1, d2q1 + d2q2) and isclose(d1q2, 0):
+                    if isclose(d1q1, d2q1 + d2q2) and d1q2 == 0:
                         sum_document2 += 1
-                    if isclose(d1q2, d2q2 + d2q1) and isclose(d1q1, 0):
+                    if isclose(d1q2, d2q2 + d2q1) and d1q1 == 0:
                         sum_document2 += 1
 
         return strictly_greater(sum_document1, sum_document2)
 
-
-@dataclass(frozen=True)
-class TFC3(LEN_Mixin, _TFC3):
-    name = "TFC3"
+    def preferences(
+        self,
+        input: Query,
+        outputs: Sequence[Document],
+    ) -> PreferenceMatrix:
+        query_unique_terms = self.term_tokenizer.unique_terms(
+            self.text_contents.contents(input),
+        )
+        query_term_pairs = [
+            (query_term1, query_term2)
+            for query_term1, query_term2 in tqdm(
+                combinations(query_unique_terms, 2),
+                desc="Query term pairs",
+                unit="pair",
+            )
+            if isclose(
+                self.index_statistics.inverse_document_frequency(query_term1),
+                self.index_statistics.inverse_document_frequency(query_term2),
+                rel_tol=self.margin_fraction,
+            )
+        ]
+        considered_query_terms = set(chain.from_iterable(query_term_pairs))
+        term_frequencies = [
+            {
+                query_term: self.text_statistics.term_frequency(output, query_term)
+                for query_term in considered_query_terms
+            }
+            for output in tqdm(outputs, desc="Term frequencies", unit="document")
+        ]
+
+        return array(
+            list(
+                tqdm(
+                    (
+                        strictly_greater(
+                            sum(
+                                1
+                                for query_term1, query_term2 in query_term_pairs
+                                if term_frequencies[i1][query_term1] != 0
+                                and term_frequencies[i1][query_term2] != 0
+                                and (
+                                    (
+                                        isclose(
+                                            term_frequencies[i2][query_term1],
+                                            term_frequencies[i1][query_term1]
+                                            + term_frequencies[i1][query_term2],
+                                        )
+                                        and term_frequencies[i2][query_term2] == 0
+                                    )
+                                    or (
+                                        isclose(
+                                            term_frequencies[i2][query_term2],
+                                            term_frequencies[i1][query_term2]
+                                            + term_frequencies[i1][query_term1],
+                                        )
+                                        and term_frequencies[i2][query_term1] == 0
+                                    )
+                                )
+                            ),
+                            sum(
+                                1
+                                for query_term1, query_term2 in query_term_pairs
+                                if term_frequencies[i2][query_term1] != 0
+                                and term_frequencies[i2][query_term2] != 0
+                                and (
+                                    (
+                                        isclose(
+                                            term_frequencies[i1][query_term1],
+                                            term_frequencies[i2][query_term1]
+                                            + term_frequencies[i2][query_term2],
+                                        )
+                                        and term_frequencies[i1][query_term2] == 0
+                                    )
+                                    or (
+                                        isclose(
+                                            term_frequencies[i1][query_term2],
+                                            term_frequencies[i2][query_term2]
+                                            + term_frequencies[i2][query_term1],
+                                        )
+                                        and term_frequencies[i1][query_term1] == 0
+                                    )
+                                )
+                            ),
+                        )
+                        for i1 in range(len(outputs))
+                        for i2 in range(len(outputs))
+                    ),
+                    desc="Compare",
+                    unit="pair",
+                )
+            ),
+            dtype=float_,
+        ).reshape((len(outputs), len(outputs)))
+
+
+TFC3: Final = lazy_inject(Tfc3Axiom)
 
 
 def _single_different_term_frequency(
-        context: IndexContext,
-        query: Query,
-        document1: RankedDocument,
-        document2: RankedDocument
-):
-    query_terms = context.term_set(query)
-    sum_term_frequency1 = 0
-    sum_term_frequency2 = 0
+    query_unique_terms: AbstractSet,
+    text_statistics: TextStatistics[Document],
+    output1: Document,
+    output2: Document,
+) -> bool:
+    sum_term_frequency1 = 0.0
+    sum_term_frequency2 = 0.0
     term_frequency_different = False
-    for term in query_terms:
-        count1 = context.term_frequency(document1, term)
-        count2 = context.term_frequency(document2, term)
+    for term in query_unique_terms:
+        count1 = text_statistics.term_frequency(output1, term)
+        count2 = text_statistics.term_frequency(output2, term)
         if count1 != count2:
             term_frequency_different = True
         sum_term_frequency1 += count1
         sum_term_frequency2 += count2
 
     return (
-            isclose(sum_term_frequency1, sum_term_frequency2) and
-            term_frequency_different
+        isclose(sum_term_frequency1, sum_term_frequency2) and term_frequency_different
     )
 
 
-@dataclass(frozen=True)
-class M_TDC(Axiom):
+@inject
+@dataclass(frozen=True, kw_only=True)
+class ModifiedTdcAxiom(Axiom[Query, Document]):
     """
     Modified TDC as in:
 
     Shi, S., Wen, J.R., Yu, Q., Song, R., Ma, W.Y.: Gravitation-based model
     for information retrieval. In: SIGIR â€™05.
     """
-    name = "M-TDC"
+
+    text_contents: TextContents[Union[Query, Document]]
+    term_tokenizer: TermTokenizer
+    index_statistics: IndexStatistics
+    text_statistics: TextStatistics[Union[Query, Document]]
 
     def preference(
-            self,
-            context: IndexContext,
-            query: Query,
-            document1: RankedDocument,
-            document2: RankedDocument
-    ):
+        self,
+        input: Query,
+        output1: Document,
+        output2: Document,
+    ) -> Preference:
+        query_terms = self.term_tokenizer.terms(
+            self.text_contents.contents(input),
+        )
+        query_unique_terms = set(query_terms)
+
         if not _single_different_term_frequency(
-                context,
-                query,
-                document1,
-                document2
+            query_unique_terms=query_unique_terms,
+            text_statistics=self.text_statistics,
+            output1=output1,
+            output2=output2,
         ):
             return 0
 
-        query_terms = context.term_set(query)
-
         score1 = 0
         score2 = 0
 
-        for query_term1, query_term2 in combinations(query_terms, 2):
-            idf_qt1 = context.inverse_document_frequency(query_term1)
-            idf_qt2 = context.inverse_document_frequency(query_term2)
+        for query_term1, query_term2 in combinations(query_unique_terms, 2):
+            idf_qt1 = self.index_statistics.inverse_document_frequency(query_term1)
+            idf_qt2 = self.index_statistics.inverse_document_frequency(query_term2)
 
             if isclose(idf_qt1, idf_qt2):
                 # Skip query term pair, as they are equally rare.
@@ -150,26 +318,22 @@ class M_TDC(Axiom):
                 # Query term 1 is rarer. Swap query terms.
                 query_term1, query_term2 = query_term2, query_term1
 
-            tf_d1_qt1 = context.term_frequency(document1, query_term1)
-            tf_d1_qt2 = context.term_frequency(document1, query_term2)
-            tf_d2_qt1 = context.term_frequency(document2, query_term1)
-            tf_d2_qt2 = context.term_frequency(document2, query_term2)
-            tf_q_qt1 = context.term_frequency(query, query_term1)
-            tf_q_qt2 = context.term_frequency(query, query_term2)
+            tf_d1_qt1 = self.text_statistics.term_frequency(output1, query_term1)
+            tf_d1_qt2 = self.text_statistics.term_frequency(output1, query_term2)
+            tf_d2_qt1 = self.text_statistics.term_frequency(output2, query_term1)
+            tf_d2_qt2 = self.text_statistics.term_frequency(output2, query_term2)
+            tf_q_qt1 = self.text_statistics.term_frequency(input, query_term1)
+            tf_q_qt2 = self.text_statistics.term_frequency(input, query_term2)
 
             if not (
-                    (
-                            isclose(tf_d1_qt1, tf_d2_qt2) and
-                            isclose(tf_d1_qt2, tf_d2_qt1)
-                    ) or
-                    tf_q_qt1 >= tf_q_qt2
+                (isclose(tf_d1_qt1, tf_d2_qt2) and isclose(tf_d1_qt2, tf_d2_qt1))
+                or tf_q_qt1 >= tf_q_qt2
             ):
                 # Term pair is valid.
                 continue
 
-            if (
-                    tf_q_qt1 < tf_q_qt2 and
-                    (tf_d1_qt1 != tf_d2_qt2 or tf_d1_qt2 != tf_d2_qt1)
+            if tf_q_qt1 < tf_q_qt2 and (
+                tf_d1_qt1 != tf_d2_qt2 or tf_d1_qt2 != tf_d2_qt1
             ):
                 # Term pair is valid.
                 continue
@@ -186,6 +350,13 @@ class M_TDC(Axiom):
         return strictly_greater(score1, score2)
 
 
-@dataclass(frozen=True)
-class LEN_M_TDC(LEN_Mixin, M_TDC):
-    name = "LEN-M-TDC"
+M_TDC: Final = lazy_inject(ModifiedTdcAxiom)
+
+
+@inject
+@dataclass(frozen=True, kw_only=True)
+class LenModifiedTdcAxiom(PreconditionMixin[Query, Document], ModifiedTdcAxiom):
+    precondition: NoInject[Precondition[Query, Document]] = field(default_factory=LEN)
+
+
+LEN_M_TDC: Final = lazy_inject(LenModifiedTdcAxiom)
